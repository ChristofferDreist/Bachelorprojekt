{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "CHOICE_SET_CSV = r'C:\\Users\\Chris\\Desktop\\DTU\\8. Semester\\Bachelorprojekt-1\\Data\\Final\\choice_set_Final_1_15_Sep23.csv'\n",
    "CHOSEN_CSV     = r'C:\\Users\\Chris\\Desktop\\DTU\\8. Semester\\Bachelorprojekt-1\\Data\\Final\\df_Sep1_15_SEP23_MORNING.csv'\n",
    "\n",
    "# Load\n",
    "df_choices = pd.read_csv(CHOICE_SET_CSV)\n",
    "df_chosen  = pd.read_csv(CHOSEN_CSV, parse_dates=['Start_Time'])\n",
    "\n",
    "# Merge on 'turngl' to get timestamp\n",
    "df = (\n",
    "    df_choices\n",
    "    .merge(df_chosen[['turngl','Start_Time']], on='turngl', how='left')\n",
    ")\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84084ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summed in‐vehicle time across modes\n",
    "tt_cols = ['sum_TT_Bus','sum_TT_Metro','sum_TT_Tog','sum_TT_Stog']\n",
    "df['in_vehicle_time'] = df[tt_cols].sum(axis=1)\n",
    "\n",
    "# Total travel time including walking\n",
    "df['TT_total'] = df['in_vehicle_time'] + df['WalkingTime']\n",
    "\n",
    "# Transfers count (raw)\n",
    "df['transfers'] = df['transfers_upd']\n",
    "\n",
    "# Within each Obs_ID, find the fastest alternative\n",
    "g = df.groupby('Obs_ID')\n",
    "df['best_TT']   = g['TT_total'].transform('min')\n",
    "df['excess_TT'] = df['TT_total'] - df['best_TT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative excess travel time\n",
    "df['rel_TT']  = df['excess_TT'] / (g['TT_total'].transform('max') - df['best_TT'])\n",
    "df['rank_TT'] = g['TT_total'].rank(method='min', ascending=True)\n",
    "\n",
    "# Relative transfers\n",
    "df['rel_transfers'] = (\n",
    "    (df['transfers'] - g['transfers'].transform('min')) /\n",
    "    (g['transfers'].transform('max') - g['transfers'].transform('min'))\n",
    ")\n",
    "df['rank_trans'] = g['transfers'].rank(method='min', ascending=True)\n",
    "\n",
    "# Relative walking time\n",
    "df['walking_time'] = df['WalkingTime']\n",
    "df['rel_walk']     = (\n",
    "    (df['WalkingTime'] - g['WalkingTime'].transform('min')) /\n",
    "    (g['WalkingTime'].transform('max') - g['WalkingTime'].transform('min'))\n",
    ")\n",
    "df['rank_walk']    = g['WalkingTime'].rank(method='min', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_dist'] = g['total_distance'].transform('min')\n",
    "df['max_dist'] = g['total_distance'].transform('max')\n",
    "df['rel_dist'] = (df['total_distance'] - df['min_dist']) / (df['max_dist'] - df['min_dist'])\n",
    "\n",
    "# Flag if alternative is longer than median OD-distance\n",
    "od_med = df.groupby('OD')['total_distance'].transform('median')\n",
    "df['long_journey'] = (df['total_distance'] > od_med).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3fa441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OD_demand = # chosen per OD\n",
    "df['OD_demand'] = g['choice'].transform('sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = {'000008603301', '000008603302', '000008603303', '000008603304', '000008603305', '000008603306', '000008603307', '000008603308', '000008603309', '000008603310', '000008603311', '000008603312', '000008603313', '000008603315', '000008603317'}\n",
    "\n",
    "m2 = {'000008603301', '000008603302', '000008603303', '000008603304', '000008603305', '000008603306', '000008603307', '000008603308', '000008603309', '000008603321', '000008603322', '000008603323', '000008603324', '000008603326', '000008603327', '000008603328'}\n",
    "\n",
    "m3 = {'8603330','8603331','8603332','8603308','8603333','8603334',\n",
    "      '8603335','8603336','8603337','8603338','8603339','8603340',\n",
    "      '8603341','8603342','8603305','8603343','8603344'}\n",
    "\n",
    "m4 = {'000008603345', '000008603346', '000008603334', '000008603333', '000008603308', '000008603332', '000008603331', '000008603330'} # Resten af M4 var ikke åbnet i september 2023\n",
    "\n",
    "\n",
    "df['orig_on_M1'] = df['origin'].astype(str).isin(m1).astype(int)\n",
    "df['dest_on_M1'] = df['destination'].astype(str).isin(m1).astype(int)\n",
    "\n",
    "df['orig_on_M2'] = df['origin'].astype(str).isin(m2).astype(int)\n",
    "df['dest_on_M2'] = df['destination'].astype(str).isin(m2).astype(int)\n",
    "\n",
    "df['orig_on_M3'] = df['origin'].astype(str).isin(m3).astype(int)\n",
    "df['dest_on_M3'] = df['destination'].astype(str).isin(m3).astype(int)\n",
    "\n",
    "df['orig_on_M4'] = df['origin'].astype(str).isin(m4).astype(int)\n",
    "df['dest_on_M4'] = df['destination'].astype(str).isin(m4).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour']    = df['Start_Time'].dt.hour + df['Start_Time'].dt.minute/60\n",
    "df['is_rush'] = ((df['Start_Time'].dt.weekday < 5) & df['hour'].between(7,9)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['freq_per_hr'] = 60.0 / df['first_headway']\n",
    "\n",
    "# Atomic mode flags\n",
    "for mode in [\"Bus\",\"Metro\",\"Tog\",\"Stog\"]:\n",
    "    df[f\"uses_{mode}\"] = df[\"ModalKomb\"].str.contains(mode).astype(int)\n",
    "\n",
    "# Relative frequency within each Obs_ID\n",
    "df['rel_freq'] = (\n",
    "    (df['freq_per_hr'] - g['freq_per_hr'].transform('min')) /\n",
    "    (g['freq_per_hr'].transform('max') - g['freq_per_hr'].transform('min'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c332db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "# Build trip to route map\n",
    "TRIPS      = r'C:\\Users\\Chris\\Desktop\\DTU\\8. Semester\\Bachelorprojekt-1\\Data\\GTFS_20230925\\trips.txt'\n",
    "STOP_TIMES = r'C:\\Users\\Chris\\Desktop\\DTU\\8. Semester\\Bachelorprojekt-1\\Data\\GTFS_20230925\\stop_times.txt'\n",
    "\n",
    "# trip_id → route_id\n",
    "trips = pd.read_csv(TRIPS, usecols=['route_id','trip_id'], dtype=str)\n",
    "trip2route = dict(zip(trips['trip_id'], trips['route_id']))\n",
    "\n",
    "# Read only the first stop of each trip\n",
    "route_times = defaultdict(list)\n",
    "with open(STOP_TIMES, newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row['stop_sequence'] == '0':\n",
    "            rid = trip2route.get(row['trip_id'])\n",
    "            if rid:\n",
    "                h,m,s = row['departure_time'].split(':')\n",
    "                t = int(h)*60 + int(m) + int(s)/60\n",
    "                route_times[rid].append(t)\n",
    "\n",
    "# Build route to median headway (in minutes) properly\n",
    "headway_map = {}\n",
    "for rid, times in route_times.items():\n",
    "    if len(times) > 1:\n",
    "        sorted_ts = np.sort(times)\n",
    "        diffs     = np.diff(sorted_ts)\n",
    "        headway_map[rid] = float(np.median(diffs))\n",
    "\n",
    "# Fallback map for missing legs\n",
    "first_leg = (\n",
    "    df[['RuteIdSeq','first_headway']]\n",
    "    .assign(first_route=lambda d: d.RuteIdSeq.str.split('-').str[0])\n",
    "    .drop_duplicates('first_route')\n",
    ")\n",
    "fallback_map = dict(zip(first_leg['first_route'], first_leg['first_headway']))\n",
    "\n",
    "# Explode alternatives → one row per leg\n",
    "df['route_list'] = df['RuteIdSeq'].str.split('-')\n",
    "exploded = df[['Obs_ID','Alt_ID','route_list']].explode('route_list')\n",
    "\n",
    "# Vectorized lookup + fallback\n",
    "exploded['headway_min'] = (\n",
    "    exploded['route_list'].map(headway_map)\n",
    "             .fillna(exploded['route_list'].map(fallback_map))\n",
    ")\n",
    "\n",
    "# Compute vehicles/hour\n",
    "exploded['freq'] = 60.0 / exploded['headway_min']\n",
    "\n",
    "# Aggregate to journey-level\n",
    "agg = exploded.groupby(['Obs_ID','Alt_ID'])['freq'].agg(\n",
    "    freq_min  = 'min',\n",
    "    freq_avg  = 'mean',\n",
    "    freq_harm = lambda F: len(F) / F.map(lambda x:1/x).sum()\n",
    ").reset_index()\n",
    "\n",
    "# Merge & clean up\n",
    "df = df.merge(agg, on=['Obs_ID','Alt_ID'], how='left')\n",
    "df.drop(columns=['first_headway','freq_per_hr','route_list'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_segments']   = df['RuteIdSeq'].str.count('-') + 1\n",
    "df['n_stops']      = df['StopNbSequence'].str.count(';') + 1\n",
    "df['avg_stop_dist']= df['total_distance'] / df['n_stops']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da6cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes_list = df['ModalKomb'].str.split('-')\n",
    "df['mode_switches'] = modes_list.apply(\n",
    "    lambda L: sum(1 for i in range(1,len(L)) if L[i] != L[i-1])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56200653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sum_transfer_dist'] = df['sum_transfer_dist']  # from raw\n",
    "df['avg_transfer_dist'] = df['sum_transfer_dist'] / df['transfers'].replace(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_OD_demand'] = np.log1p(df['OD_demand'])\n",
    "df['rel_TT_x_uses_Bus']    = df['rel_TT'] * df['uses_Bus']\n",
    "df['rel_TT_x_uses_Metro']  = df['rel_TT'] * df['uses_Metro']\n",
    "df['rel_trans_x_switches']= df['rel_transfers'] * df['mode_switches']\n",
    "df['rel_walk_x_long_journey'] = df['rel_walk'] * df['long_journey']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f0b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cols = [\n",
    "    'turngl','origin','destination','TT_choice(min)','RuteIdSeq',\n",
    "    'StopNbSequence','total_distance','transfers_upd','ModalKomb',\n",
    "    'sum_transfer_dist','Alt_ID','Planned_TT','first_headway',\n",
    "    'sum_TT_Bus','sum_TT_Tog','sum_TT_Stog','sum_TT_Metro',\n",
    "    'WalkingTime','Start_Time'\n",
    "]\n",
    "\n",
    "# Metadata columns we still want in the final file:\n",
    "keep_cols = ['Obs_ID','OD','choice']\n",
    "\n",
    "# Now everything else in df is an engineered feature:\n",
    "engineered_cols = [c for c in df.columns \n",
    "                   if c not in raw_cols + keep_cols]\n",
    "\n",
    "# Sanity check: no overlap with keep_cols or raw_cols\n",
    "assert set(engineered_cols).isdisjoint(set(raw_cols + keep_cols))\n",
    "\n",
    "print(f\"Saving {len(keep_cols)} metadata + {len(engineered_cols)} engineered features:\")\n",
    "print(\"  metadata:\", keep_cols)\n",
    "print(\"  features:\", engineered_cols[:5], \"…\", engineered_cols[-5:])\n",
    "\n",
    "# Safe to parquet\n",
    "out_cols = keep_cols + engineered_cols\n",
    "df[out_cols].to_parquet('features_full.parquet', index=False)\n",
    "print(\"Saved 'features_full.parquet' with columns:\")\n",
    "print(df[out_cols].columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorprojekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
