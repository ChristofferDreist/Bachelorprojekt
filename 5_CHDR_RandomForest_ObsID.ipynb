{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8518239",
   "metadata": {},
   "source": [
    "# Imports & Load Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Load the final feature table\n",
    "df = pd.read_parquet('features_final.parquet')\n",
    "print(\"Loaded features:\", df.shape)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e980c",
   "metadata": {},
   "source": [
    "# Define Features, Labels & Groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7162bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns except metadata\n",
    "feature_cols = [c for c in df.columns if c not in ['choice','OD','Obs_ID']]\n",
    "\n",
    "X_full = df[feature_cols]\n",
    "y_full = df['choice']\n",
    "groups_full = df['Obs_ID']\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features:\", feature_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c030a71",
   "metadata": {},
   "source": [
    "# Section A: Pilot‐OD Random Forest\n",
    "\n",
    "First we subset to our 12 “pilot” ODs and train/test a Random Forest there, to see how it performs on our chosen case study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a) Define the 12 pilot ODs\n",
    "pilot_ods = [\n",
    "    '8603305-8603307','8603313-8603308','8600741-8600642',\n",
    "    '8600636-8603308','8600681-8603308','8600677-8603308',\n",
    "    '8600657-8603308','8600695-8603308','8600678-8603308',\n",
    "    '8603317-8603339','8603334-8603331','8603336-8603331'\n",
    "]\n",
    "\n",
    "pilot_df = df[df['OD'].isin(pilot_ods)].copy()\n",
    "X_pilot = pilot_df[feature_cols]\n",
    "y_pilot = pilot_df['choice']\n",
    "groups_pilot = pilot_df['Obs_ID']\n",
    "\n",
    "print(\"Pilot set shape:\", pilot_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split on Obs_ID for pilot set\n",
    "pilot_ids = groups_pilot.unique()\n",
    "train_ids, test_ids = train_test_split(pilot_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = pilot_df['Obs_ID'].isin(train_ids)\n",
    "test_mask  = ~train_mask\n",
    "\n",
    "X_train_p = X_pilot[train_mask]\n",
    "X_test_p  = X_pilot[test_mask]\n",
    "y_train_p = y_pilot[train_mask]\n",
    "y_test_p  = y_pilot[test_mask]\n",
    "\n",
    "# Fit Random Forest on pilot\n",
    "rf_p = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_p.fit(X_train_p, y_train_p)\n",
    "\n",
    "\n",
    "joblib.dump(rf_p, 'rf_pilot.joblib')\n",
    "print(\"Saved pilot RF to rf_pilot.joblib\")\n",
    "\n",
    "# Evaluate pilot performance\n",
    "y_pred_p  = rf_p.predict(X_test_p)\n",
    "y_proba_p = rf_p.predict_proba(X_test_p)[:,1]\n",
    "\n",
    "acc_p = accuracy_score(y_test_p, y_pred_p)\n",
    "ll_p  = log_loss(y_test_p, y_proba_p)\n",
    "\n",
    "# choice‐set accuracy: did the top‐scoring alt match the actual choice?\n",
    "test_p = pilot_df[test_mask].copy()\n",
    "test_p['score'] = y_proba_p\n",
    "cs_p = test_p.groupby('Obs_ID') \\\n",
    "             .apply(lambda g: int(g.loc[g.score.idxmax(),'choice'])) \\\n",
    "             .mean()\n",
    "\n",
    "print(f\"Pilot RF — Accuracy: {acc_p:.3f}, Log-loss: {ll_p:.3f}, Choice-set acc: {cs_p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilot: Top 10 Feature Importances\n",
    "import numpy as np\n",
    "\n",
    "imp_p = rf_p.feature_importances_\n",
    "idx_p = np.argsort(imp_p)[::-1][:10]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.barh(np.array(feature_cols)[idx_p][::-1], imp_p[idx_p][::-1])\n",
    "plt.title(\"Pilot: Top 10 Feature Importances\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf6659",
   "metadata": {},
   "source": [
    "# Section B: Full‐Network Random Forest\n",
    "\n",
    "Now we repeat the same process on the entire dataset to see overall performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6cef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split on Obs_ID for full network\n",
    "full_ids = groups_full.unique()\n",
    "train_ids, test_ids = train_test_split(full_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = df['Obs_ID'].isin(train_ids)\n",
    "test_mask  = ~train_mask\n",
    "\n",
    "X_train_f = X_full[train_mask]\n",
    "X_test_f  = X_full[test_mask]\n",
    "y_train_f = y_full[train_mask]\n",
    "y_test_f  = y_full[test_mask]\n",
    "\n",
    "# Fit Random Forest on full network\n",
    "rf_f = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_f.fit(X_train_f, y_train_f)\n",
    "\n",
    "joblib.dump(rf_f, 'rf_full.joblib')\n",
    "print(\"Saved full RF to rf_full.joblib\")\n",
    "\n",
    "# Evaluate full‐network performance\n",
    "y_pred_f  = rf_f.predict(X_test_f)\n",
    "y_proba_f = rf_f.predict_proba(X_test_f)[:,1]\n",
    "\n",
    "acc_f = accuracy_score(y_test_f, y_pred_f)\n",
    "ll_f  = log_loss(y_test_f, y_proba_f)\n",
    "\n",
    "test_f = df[test_mask].copy()\n",
    "test_f['score'] = y_proba_f\n",
    "cs_f = test_f.groupby('Obs_ID') \\\n",
    "             .apply(lambda g: int(g.loc[g.score.idxmax(),'choice'])) \\\n",
    "             .mean()\n",
    "\n",
    "print(f\"Full RF — Accuracy: {acc_f:.3f}, Log-loss: {ll_f:.3f}, Choice-set acc: {cs_f:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full: Top 10 Feature Importances\n",
    "imp_f = rf_f.feature_importances_\n",
    "idx_f = np.argsort(imp_f)[::-1][:10]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.barh(np.array(feature_cols)[idx_f][::-1], imp_f[idx_f][::-1])\n",
    "plt.title(\"Full: Top 10 Feature Importances\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b29d2",
   "metadata": {},
   "source": [
    "# Pilot vs Full Comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5939b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Setting': ['Pilot','Full network'],\n",
    "    'Accuracy': [acc_p, acc_f],\n",
    "    'Log-loss': [ll_p, ll_f],\n",
    "    'Choice-set accuracy': [cs_p, cs_f]\n",
    "})\n",
    "print(results.to_string(index=False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorprojekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
