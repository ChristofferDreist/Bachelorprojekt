{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d00286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, brier_score_loss, classification_report\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_parquet('features_full.parquet')\n",
    "feature_cols = [c for c in df.columns if c not in ['choice','OD','Obs_ID']]\n",
    "X = df[feature_cols].values\n",
    "y = df['choice'].values\n",
    "groups = df['OD'].values # Change to OBS_ID if you want to group by Obs_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV setup\n",
    "n_splits = 5\n",
    "gkf      = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': [], 'balanced_acc': [],\n",
    "    'precision': [], 'recall': [], 'f1': [],\n",
    "    'roc_auc': [], 'brier': [],\n",
    "    'baseline_acc': [], 'baseline_bal_acc': [],\n",
    "    'group_acc': [], 'baseline_group_acc': []\n",
    "}\n",
    "\n",
    "# Prepare calibration plot\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot([0,1], [0,1], 'k--', label='Perfect calibration')\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) CV loop\n",
    "# ------------------------------------------------------------------------------\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups), start=1):\n",
    "    print(f\"\\n=== Fold {fold}/{n_splits} ===\")\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Subset of the original DataFrame for later group‐level ops\n",
    "    val_df = df.iloc[val_idx].copy().reset_index(drop=True)\n",
    "\n",
    "    # Impute\n",
    "    imp = SimpleImputer(strategy='median')\n",
    "    X_tr_imp  = imp.fit_transform(X_tr)\n",
    "    X_val_imp = imp.transform(X_val)\n",
    "\n",
    "    # Train TabNet\n",
    "    clf = TabNetClassifier(verbose=0, device_name='auto')\n",
    "    clf.fit(\n",
    "        X_tr_imp, y_tr,\n",
    "        eval_set=[(X_val_imp, y_val)],\n",
    "        eval_name=['val'],\n",
    "        eval_metric=['auc', 'accuracy'],\n",
    "        max_epochs=100, patience=10,\n",
    "        batch_size=1024, virtual_batch_size=128,\n",
    "        compute_importance=True\n",
    "    )\n",
    "\n",
    "    # Row-level predictions\n",
    "    y_proba = clf.predict_proba(X_val_imp)[:, 1]\n",
    "    y_pred  = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "    # Attach to val_df\n",
    "    val_df['proba']       = y_proba\n",
    "    val_df['pred_label']  = y_pred\n",
    "    # baseline per‐row pred: choose rank_TT == 1\n",
    "    val_df['pred_base']   = (val_df['rank_TT'] == 1).astype(int)\n",
    "\n",
    "    # **Per-row metrics**\n",
    "    acc      = accuracy_score(y_val, y_pred)\n",
    "    bal_acc  = balanced_accuracy_score(y_val, y_pred)\n",
    "    prec     = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec      = recall_score(y_val, y_pred, zero_division=0)\n",
    "    f1       = f1_score(y_val, y_pred, zero_division=0)\n",
    "    roc_auc  = roc_auc_score(y_val, y_proba)\n",
    "    brier    = brier_score_loss(y_val, y_proba)\n",
    "\n",
    "    base_acc = accuracy_score(y_val, val_df['pred_base'])\n",
    "    base_bal = balanced_accuracy_score(y_val, val_df['pred_base'])\n",
    "\n",
    "    # **Group‐level accuracy\n",
    "    #  - model: check if for each Obs_ID, the row with max proba has choice==1\n",
    "    group_hits = (\n",
    "        val_df\n",
    "        .groupby('Obs_ID')\n",
    "        .apply(lambda g: g.loc[g['proba'].idxmax(), 'choice'] == 1)\n",
    "    )\n",
    "    group_acc = group_hits.mean()\n",
    "\n",
    "    #  - baseline: for each Obs_ID, the row with rank_TT==1 should match choice==1 #This is fastest time baseline and deprecated. In report it's matched against\n",
    "    # fewest transfers then fastest time\n",
    "    base_hits = (\n",
    "        val_df\n",
    "        .groupby('Obs_ID')\n",
    "        .apply(lambda g: g.loc[g['pred_base']==1, 'choice'].iat[0] == 1)\n",
    "    )\n",
    "    baseline_group_acc = base_hits.mean()\n",
    "\n",
    "    # Store metrics\n",
    "    metrics['accuracy'].append(acc)\n",
    "    metrics['balanced_acc'].append(bal_acc)\n",
    "    metrics['precision'].append(prec)\n",
    "    metrics['recall'].append(rec)\n",
    "    metrics['f1'].append(f1)\n",
    "    metrics['roc_auc'].append(roc_auc)\n",
    "    metrics['brier'].append(brier)\n",
    "    metrics['baseline_acc'].append(base_acc)\n",
    "    metrics['baseline_bal_acc'].append(base_bal)\n",
    "    metrics['group_acc'].append(group_acc)\n",
    "    metrics['baseline_group_acc'].append(baseline_group_acc)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Model (per-row)    → acc: {acc:.3f}, bal_acc: {bal_acc:.3f}, \"\n",
    "          f\"AUC: {roc_auc:.3f}, Brier: {brier:.3f}\")\n",
    "    print(f\"Model (group)      → accuracy: {group_acc:.3f}\")\n",
    "    print(f\"Baseline (per-row) → acc: {base_acc:.3f}, bal_acc: {base_bal:.3f}\")\n",
    "    print(f\"Baseline (group)   → accuracy: {baseline_group_acc:.3f}\")\n",
    "\n",
    "    print(\"\\nClassification Report (per-row):\")\n",
    "    print(classification_report(y_val, y_pred, zero_division=0))\n",
    "\n",
    "    # Calibration curve\n",
    "    frac_pos, mean_pred = calibration_curve(y_val, y_proba, n_bins=10)\n",
    "    plt.plot(mean_pred, frac_pos, 'o-', label=f'Fold {fold}')\n",
    "\n",
    "# CV summary & plots\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Reliability diagram (GroupKFold CV)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "cv_df = pd.DataFrame(metrics)\n",
    "print(\"\\nCross-validation summary (mean ± std):\")\n",
    "print(cv_df.agg(['mean','std']).T)\n",
    "\n",
    "# Bar chart: group accuracy per fold\n",
    "plt.figure(figsize=(6,4))\n",
    "folds = np.arange(1, n_splits+1)\n",
    "plt.bar(folds - 0.15, metrics['group_acc'], width=0.3, label='Model')\n",
    "plt.bar(folds + 0.15, metrics['baseline_group_acc'], width=0.3, label='Baseline')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Group-level Accuracy')\n",
    "plt.title('Choice-set Accuracy per Fold')\n",
    "plt.xticks(folds)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorprojekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
