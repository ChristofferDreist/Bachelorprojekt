{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Load the features dataset\n",
    "df = pd.read_parquet('features_full.parquet')  # switch to ('features_final.parquet') if you want smaller choice set\n",
    "# Define features, label, and groups\n",
    "features = ['rel_TT', 'rel_transfers', 'rel_walk', 'excess_TT', 'rel_freq']\n",
    "# features = [c for c in df.columns if c not in ['choice','OD','Obs_ID']] # Remove comment if you want full feature set insetad\n",
    "X = df[features]\n",
    "\n",
    "y = df['choice']\n",
    "groups = df['OD'] # Switch to 'Obs_ID' if you want per-trip grouping\n",
    "\n",
    "\n",
    "print(\"Total samples:\", len(df), \"Total observations:\", groups.nunique())\n",
    "print(\"Features:\", features)\n",
    "print(\"Sample X snippet:\\n\", X.head(5))\n",
    "print(\"Sample y snippet:\\n\", y.head(5))\n",
    "print(\"Unique groups (Obs_ID) snippet:\\n\", groups.head(5))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Set up grouped 5-fold cross-validation\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "fold_metrics = []\n",
    "feature_importances = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups), start=1):\n",
    "    # Split data into training and test for this fold\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    # Initialize and train Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    # Predict probabilities on the test set\n",
    "    y_proba = rf.predict_proba(X_test)[:, 1]  # probability of class 1 (chosen)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    ll = log_loss(y_test, rf.predict_proba(X_test))\n",
    "    # Compute choice-set accuracy\n",
    "    test_groups = groups.iloc[test_idx].values\n",
    "    df_test = pd.DataFrame({'Obs_ID': test_groups, 'true_choice': y_test.values, 'pred_prob': y_proba})\n",
    "    correct_choice_count = 0\n",
    "    for obs_id, grp in df_test.groupby('Obs_ID'):\n",
    "        # Identify the alternative with highest predicted probability in this observation\n",
    "        idx_max = grp['pred_prob'].idxmax()\n",
    "        chosen_flag = grp.loc[idx_max, 'true_choice']  # actual choice flag of that predicted route\n",
    "        if chosen_flag == 1:\n",
    "            correct_choice_count += 1\n",
    "    choice_set_acc = correct_choice_count / df_test['Obs_ID'].nunique()\n",
    "    # Store metrics and feature importances\n",
    "    fold_metrics.append((acc, ll, choice_set_acc))\n",
    "    feature_importances.append(rf.feature_importances_)\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.3f}, Log-Loss = {ll:.3f}, Choice-Set Accuracy = {choice_set_acc:.3f}\")\n",
    "\n",
    "# Compute average and std of metrics across folds\n",
    "metrics_array = pd.DataFrame(fold_metrics, columns=['Accuracy', 'LogLoss', 'ChoiceSetAcc'])\n",
    "avg_metrics = metrics_array.mean()\n",
    "std_metrics = metrics_array.std()\n",
    "print(\"\\nCV Average Metrics:\")\n",
    "for metric in ['Accuracy', 'LogLoss', 'ChoiceSetAcc']:\n",
    "    print(f\"{metric}: {avg_metrics[metric]:.3f} ± {std_metrics[metric]:.3f}\")\n",
    "\n",
    "\n",
    "importances = np.vstack(feature_importances)\n",
    "mean_imp = importances.mean(axis=0)\n",
    "std_imp  = importances.std(axis=0)\n",
    "\n",
    "# Top 10 features\n",
    "top_idx = np.argsort(mean_imp)[::-1][:10]\n",
    "top_features = np.array(features)[top_idx]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(\n",
    "    top_features[::-1],\n",
    "    mean_imp[top_idx][::-1],\n",
    "    xerr=std_imp[top_idx][::-1]\n",
    ")\n",
    "plt.xlabel(\"Mean Feature Importance\")\n",
    "plt.title(\"Top 10 Feature Importances (± Std)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorprojekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
